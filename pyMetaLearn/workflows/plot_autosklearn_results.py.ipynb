{
 "metadata": {
  "name": "",
  "signature": "sha256:8c805280d4fe7974d9121038d209c5999f2f9e25fffb24f5f41c5633d5f34aa6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from argparse import ArgumentParser\n",
      "from collections import OrderedDict\n",
      "import cPickle\n",
      "import glob\n",
      "import itertools\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import scipy.stats\n",
      "import sys\n",
      "\n",
      "%matplotlib inline\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib import rc\n",
      "rc('text', usetex=True)\n",
      "\n",
      "import HPOlib.Plotting.plot_util as plot_util\n",
      "import HPOlib.Plotting.generateTexTable as generate_tex_table\n",
      "import HPOlib.Plotting.plotTraceWithStd_perEval as plotTraceWithStd_perEval\n",
      "import HPOlib.Plotting.statistics as statistics\n",
      "\n",
      "import pyMetaLearn.openml.manage_openml_data\n",
      "import pyMetaLearn.metafeatures.metafeatures as mf_module\n",
      "from pyMetaLearn.openml.openml_task import OpenMLTask\n",
      "import pyMetaLearn.workflows.plot_utils as meta_plot_util"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ground_truth_dir = \"/home/feurerm/thesis/experiments/2014_05_16_MiniAutoSklearn_meta/\"\n",
      "experiments_directory = \"/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/\"\n",
      "plot_dir = os.path.join(experiments_directory, \"plots\")\n",
      "pyMetaLearn.openml.manage_openml_data.set_local_directory(\n",
      "    \"/home/feurerm/thesis/datasets/openml/\")\n",
      "local_directory = pyMetaLearn.openml.manage_openml_data.get_local_directory()\n",
      "openml_dataset_dir = os.path.join(local_directory, \"datasets\")\n",
      "    \n",
      "num_folds = 3\n",
      "try:\n",
      "    os.mkdir(plot_dir)\n",
      "except:\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset_list = glob.glob(os.path.join(openml_dataset_dir, \"did*.xml\"))\n",
      "datasets = []\n",
      "dataset_names = []\n",
      "for dataset_filename in dataset_list:\n",
      "    did = os.path.split(dataset_filename)[1]\n",
      "    did = int(did.replace(\"did\", \"\").replace(\".xml\", \"\"))\n",
      "\n",
      "    task_file = os.path.join(pyMetaLearn\n",
      "                .openml.manage_openml_data.get_local_directory(),\n",
      "                \"custom_tasks\", \"did_%d.pkl\" % did)\n",
      "    if not os.path.exists(task_file):\n",
      "        # print \"Skipping dataset %s\" % dataset_filename\n",
      "        continue\n",
      "        \n",
      "    with open(task_file) as fh:\n",
      "        task_dict = cPickle.load(fh)\n",
      "        \n",
      "    dataset = pyMetaLearn.openml.manage_openml_data.get_local_dataset(task_dict['data_set_id'])\n",
      "    dataset_names.append(dataset._name)\n",
      "    \n",
      "    datasets.append(did)\n",
      "datasets = datasets\n",
      "datasets.sort()\n",
      "\n",
      "print datasets, len(datasets)\n",
      "print dataset_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 171, 181, 182, 183, 186, 188] 57\n",
        "[u'vehicle', u'anneal.ORIG', u'segment', u'pendigits', u'mushroom', u'labor', u'abalone', u'diabetes', u'car', u'autos', u'mfeat-fourier', u'primary-tumor', u'waveform-5000', u'credit-a', u'letter', u'postoperative-patient-data', u'vowel', u'eucalyptus', u'cylinder-bands', u'ionosphere', u'mfeat-karhunen', u'balance-scale', u'mfeat-morphological', u'liver-disorders', u'dermatology', u'vote', u'breast-cancer', u'credit-g', u'soybean', u'arrhythmia', u'nursery', u'hepatitis', u'cmc', u'heart-c', u'glass', u'braziltourism', u'iris', u'heart-statlog', u'page-blocks', u'breast-w', u'heart-h', u'yeast', u'tae', u'haberman', u'mfeat-pixel', u'optdigits', u'mfeat-factors', u'satimage', u'lymph', u'audiology', u'ecoli', u'tic-tac-toe', u'spambase', u'zoo', u'sonar', u'mfeat-zernike', u'kr-vs-kp']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here could be code get the metafeatures of a single dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Assemble the list of optimizers\n",
      "bootstraps =  (2,) # 5) #, 10)\n",
      "distance = (\"l1\", \"l2\")# \"learned\")\n",
      "metafeature_subset = mf_module.subsets\n",
      "\n",
      "optimizers = OrderedDict([\n",
      "    (\"SMAC\", \"%s/smac_2_06_01-dev_*/smac_2_06_01-dev.pkl\"),\n",
      "    (\"random\", \"%s/random_hyperopt_august2013_mod*/random_hyperopt_august2013_mod.pkl\"),\n",
      "    (\"TPE\", \"%s/hyperopt_august2013_mod_*/hyperopt_august2013_mod.pkl\"),\n",
      "    #(\"SMAC(WS5,l1,all)\", \"%s/bootstrapped5_l1_allsmac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"SMAC(WS5,l1,pfahringer)\", \"%s/bootstrapped5_l1_pfahringer_2000_experiment1smac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"SMAC(WS5,l1,yogatama)\", \"%s/bootstrapped5_l1_yogotama_2014smac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"SMAC(WS5,learned,all)\", \"%s/bootstrapped5_learned_distance_allsmac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"SMAC(WS5,learned,pfahringer)\", \"%s/bootstrapped5_learned_distance_pfahringer_2000_experiment1smac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"MI-SMAC(10,$L_1$,all)\", \"%s/bootstrapped10_l1_allsmac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"MI-SMAC(10,$L_1$,landmarking)\", \"%s/bootstrapped10_l1_pfahringer_2000_experiment1smac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"MI-SMAC(15,$L_1$,all)\", \"%s/bootstrapped15_l1_allsmac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"MI-SMAC(15,$L_1$,landmarking)\", \"%s/bootstrapped15_l1_pfahringer_2000_experiment1smac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    (\"MI-SMAC(20,$L_1$,all)\", \"%s/bootstrapped20_l1_allsmac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    (\"MI-SMAC(20,$L_1$,landmarking)\", \"%s/bootstrapped20_l1_pfahringer_2000_experiment1smac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    (\"MI-SMAC(25,$L_1$,all)\", \"%s/bootstrapped25_l1_allsmac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    (\"MI-SMAC(25,$L_1$,landmarking)\", \"%s/bootstrapped25_l1_pfahringer_2000_experiment1smac_warmstart_*/*smac_warmstart.pkl\")])\n",
      "    #(\"MI-SMAC(30,$L_1$,all)\", \"%s/bootstrapped30_l1_allsmac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"MI-SMAC(30,$L_1$,landmarking)\", \"%s/bootstrapped30_l1_pfahringer_2000_experiment1smac_warmstart_*/*smac_warmstart.pkl\")])\n",
      "    #(\"SMAC(WS10,l1,yogatama)\", \"%s/bootstrapped5_l1_yogotama_2014smac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"SMAC(WS10,learned,all)\", \"%s/bootstrapped10_learned_distance_allsmac_warmstart_*/*smac_warmstart.pkl\"),\n",
      "    #(\"SMAC(WS10,learned,pfahringer)\", \"%s/bootstrapped10_learned_distance_pfahringer_2000_experiment1smac_warmstart_*/*smac_warmstart.pkl\")])\n",
      "    #(\"SMAC/WS2\", \"%s/bootstrapped2_learnedspearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"), \n",
      "    #(\"SMAC/WS5\", \"%s/bootstrapped5_learnedspearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\")])\n",
      "\n",
      "#for dist, subset in itertools.product(distance, metafeature_subset, repeat=1):\n",
      "#    optimizers[\"ML_%s_%s\" % (dist, subset)] = \\\n",
      "#        \"%s\" + \"/%s_%smetalearn_optimizer*/*metalearn_optimizer.pkl\" % (dist, subset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_folds = 1\n",
      "# Plot the error trace over all experiments\n",
      "include_in_plots = {\"\": optimizers,\n",
      "                    \"smbo\": [\"SMAC\", \"TPE\", \"random\"],\n",
      "                    \"bs\": [\"SMAC\", \"MI-SMAC(10,$L_1$,all)\", \"MI-SMAC(10,$L_1$,landmarking)\"],\n",
      "                    \"smbo+best\": [\"SMAC\", \"TPE\", \"random\", \"MI-SMAC(10,$L_1$,landmarking)\"]}\n",
      "\n",
      "for iip in include_in_plots:\n",
      "    try:\n",
      "        print os.path.join(\"%s\" % plot_dir, \"%s\" % iip)\n",
      "        os.makedirs(os.path.join(\"%s\" % plot_dir, \"%s\" % iip))\n",
      "    except Exception as e:\n",
      "        print e\n",
      "        \n",
      "    gigantic_pickle_list = [[] for optimizer in include_in_plots[iip]]\n",
      "    for idx, dataset in enumerate(datasets):\n",
      "        dataset_rankings = np.zeros((50, len(include_in_plots[iip])), dtype=np.float64)\n",
      "        for fold in range(num_folds):\n",
      "            dataset_dir = \"did_%d_fold%d\" % (dataset, fold)\n",
      "            exp_dir = os.path.join(experiments_directory, dataset_dir)\n",
      "            argument_list = []\n",
      "            for optimizer in include_in_plots[iip]:\n",
      "                pkls = glob.glob(optimizers[optimizer] % exp_dir)\n",
      "                argument_list.append(optimizer)\n",
      "                argument_list.extend(pkls)\n",
      "            try:\n",
      "                pkl_list_main, name_list_main = plot_util.get_pkl_and_name_list(argument_list)\n",
      "            except ValueError as e:\n",
      "                print \"Value Error in dataset directory %s\" % dataset_dir\n",
      "                raise ValueError\n",
      "            for i, optimizer in enumerate(include_in_plots[iip]):\n",
      "                gigantic_pickle_list[i].extend(pkl_list_main[i])\n",
      "        \n",
      "    for file_suffix in [\"png\", \"pdf\"]:\n",
      "        plotTraceWithStd_perEval.main(gigantic_pickle_list, name_list_main, True,\n",
      "                                      save=\"%s/%s/all_datasets_error.%s\" % (plot_dir, iip, file_suffix),\n",
      "                                      markers=False, linewidth=1, linestyle=True, y_max=0.4)\n",
      "        plotTraceWithStd_perEval.main(gigantic_pickle_list, name_list_main, True,\n",
      "                                      save=\"%s/%s/all_datasets_log_error.%s\" % (plot_dir, iip, file_suffix),\n",
      "                                      log=True, markers=False, linewidth=1, linestyle=True, y_max=-0.5, y_min=-0.9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the per-dataset error traces\n",
      "best_parameters = dict()\n",
      "\n",
      "include_in_plots = {\"\": optimizers,\n",
      "                    \"smbo\": [\"SMAC\", \"TPE\", \"random\"],\n",
      "                    \"bs\": [\"SMAC\", \"MI-SMAC(10,$L_1$,all)\", \"MI-SMAC(10,$L_1$,landmarking)\"],\n",
      "                    \"smbo+best\": [\"SMAC\", \"TPE\", \"random\", \"MI-SMAC(10,$L_1$,landmarking)\"]}\n",
      "\n",
      "for iip in include_in_plots:\n",
      "    try:\n",
      "        print os.path.join(\"%s\" % plot_dir, \"%s\" % iip)\n",
      "        os.makedirs(os.path.join(\"%s\" % plot_dir, \"%s\" % iip))\n",
      "    except Exception as e:\n",
      "        print e\n",
      "    \n",
      "    for idx, dataset in enumerate(datasets):\n",
      "        for fold in range(num_folds):\n",
      "            dataset_dir = \"%s/did_%d_fold%d\" % (experiments_directory, dataset, fold)\n",
      "            plot_suffix = \"did_%d_fold%d\" % (dataset, fold)\n",
      "            if not os.path.isdir(dataset_dir) or \"did\" not in dataset_dir:\n",
      "                continue\n",
      "\n",
      "            argument_list = []\n",
      "            for optimizer in optimizers:\n",
      "                if optimizer in include_in_plots[iip]:\n",
      "                    pkls = glob.glob(optimizers[optimizer] % dataset_dir)\n",
      "                    argument_list.append(optimizer)\n",
      "                    argument_list.extend(pkls)\n",
      "\n",
      "            pkl_list_main, name_list_main = plot_util.get_pkl_and_name_list(argument_list)\n",
      "\n",
      "            ground_truth = meta_plot_util.find_ground_truth(os.path.join(ground_truth_dir,\n",
      "                                                            \"did_%d_fold%s\" % (dataset, fold),\n",
      "                                                            \"sequential_optimization_*_\",\n",
      "                                                            \"sequential.pkl\"))\n",
      "            if not ground_truth:\n",
      "                continue\n",
      "\n",
      "            ########################################################################\n",
      "            # Plot error traces for one dataset\n",
      "            optimum, trial_index = plot_util.get_best_value_and_index(ground_truth)\n",
      "            best_parameters[dataset] = ground_truth['trials'][trial_index]['params']\n",
      "\n",
      "            for file_suffix in [\"pdf\"]:#, \"png\"]:\n",
      "                #plotTraceWithStd_perEval.main(pkl_list_main, name_list_main, True, \n",
      "                #                          save=\"%s/%s/error_trace_%s.%s\" % (plot_dir, iip, plot_suffix, file_suffix),\n",
      "                #                          markers=False, linewidth=1, linestyle=True);\n",
      "                \n",
      "                #plotTraceWithStd_perEval.main(pkl_list_main, name_list_main, True, log=True, \n",
      "                #                          save=\"%s/%s/error_trace_log_%s.%s\" % (plot_dir, iip, plot_suffix, file_suffix),\n",
      "                #                          markers=False, linewidth=1, linestyle=True);\n",
      "\n",
      "                plotTraceWithStd_perEval.main(pkl_list_main, name_list_main, True, optimum=optimum,\n",
      "                                          save=\"%s/%s/optimum_error_trace_%s.%s\" % (plot_dir, iip, plot_suffix, file_suffix),\n",
      "                                          markers=False, linewidth=1, linestyle=True);\n",
      "                \n",
      "                #plotTraceWithStd_perEval.main(pkl_list_main, name_list_main, True, optimum=optimum, log=True,\n",
      "                #                          save=\"%s/%s/optimum_error_trace_log_%s.%s\" % (plot_dir, iip, plot_suffix, file_suffix),\n",
      "                #                          markers=False, linewidth=1, linestyle=True);\n",
      "                \n",
      "        \n",
      "# Plot this to a file or something...\n",
      "# for idx, dataset in enumerate(datasets):\n",
      "#     print dataset, dataset_names[idx], best_parameters[dataset]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do the statistical stuff\n",
      "include_in_plots = {\"\": optimizers,\n",
      "                    \"smbo\": [\"SMAC\", \"TPE\", \"random\"],\n",
      "                    \"bs\": [\"SMAC\", \"MI-SMAC(10,$L_1$,all)\", \"MI-SMAC(10,$L_1$,landmarking)\"],\n",
      "                    \"smbo+best\": [\"SMAC\", \"TPE\", \"random\", \"MI-SMAC(10,$L_1$,landmarking)\"]}\n",
      "reload(meta_plot_util)\n",
      "for iip in include_in_plots:\n",
      "    try:\n",
      "        print os.path.join(\"%s\" % plot_dir, \"%s\" % iip)\n",
      "        os.makedirs(os.path.join(\"%s\" % plot_dir, \"%s\" % iip))\n",
      "    except Exception as e:\n",
      "        print e\n",
      "    \n",
      "    trial_list_per_dataset = []\n",
      "    trial_list_per_dataset2 = []\n",
      "    for fold in range(num_folds):\n",
      "        for idx, dataset in enumerate(datasets):\n",
      "            dataset_dir = \"%s/did_%d_fold%d\" % (experiments_directory, dataset, fold)\n",
      "            if not os.path.isdir(dataset_dir) or \"did\" not in dataset_dir:\n",
      "                continue\n",
      "\n",
      "            argument_list = []\n",
      "            for optimizer in optimizers:\n",
      "                \n",
      "                if optimizer not in [\"MI-SMAC(20,$L_1$,landmarking)\", \"MI-SMAC(25,$L_1$,landmarking)\", 'SMAC']:\n",
      "                    continue\n",
      "                if optimizer in include_in_plots[iip]:\n",
      "                    pkls = glob.glob(optimizers[optimizer] % dataset_dir)\n",
      "                    argument_list.append(optimizer)\n",
      "                    argument_list.extend(pkls)\n",
      "                        \n",
      "            pkl_list_main, name_list_main = plot_util.get_pkl_and_name_list(argument_list)\n",
      "            trial_list_per_dataset.append(pkl_list_main)\n",
      "\n",
      "    for file_suffix in [\"png\", \"pdf\"]:\n",
      "        meta_plot_util.plot_summed_wins_of_optimizers(\n",
      "            trial_list_per_dataset, name_list_main, legend_ncols=2,\n",
      "            save=(\"%s/%s/percentage_of_wins_\" % (plot_dir, iip.replace(\"/\", \"_\")) + \"%s.\" + file_suffix))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/\n",
        "[Errno 17] File exists: '/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/'\n",
        "/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/smbo"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Errno 17] File exists: '/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/smbo'\n",
        "/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/smbo+best"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Errno 17] File exists: '/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/smbo+best'\n",
        "/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/bs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Errno 17] File exists: '/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/bs'\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/feurerm/thesis/virtualenvs/development/local/lib/python2.7/site-packages/matplotlib/axes.py:2760: UserWarning: Attempting to set identical bottom==top results\n",
        "in singular transformations; automatically expanding.\n",
        "bottom=0, top=0.0\n",
        "  + 'bottom=%s, top=%s') % (bottom, top))\n",
        "/home/feurerm/thesis/virtualenvs/development/local/lib/python2.7/site-packages/matplotlib/axes.py:2760: UserWarning: Attempting to set identical bottom==top results\n",
        "in singular transformations; automatically expanding.\n",
        "bottom=-0.0, top=0\n",
        "  + 'bottom=%s, top=%s') % (bottom, top))\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the rankings\n",
      "num_folds = 1\n",
      "include_in_plots = {\"\": optimizers,\n",
      "                    \"smbo\": [\"SMAC\", \"TPE\", \"random\"],\n",
      "                    \"bs\": [\"SMAC\", \"MI-SMAC(10,$L_1$,all)\", \"MI-SMAC(10,$L_1$,landmarking)\"],\n",
      "                    \"smbo+best\": [\"SMAC\", \"TPE\", \"random\", \"MI-SMAC(10,$L_1$,landmarking)\"]}\n",
      "rankings = {}\n",
      "\n",
      "for iip in include_in_plots:\n",
      "    num_datasets = 0\n",
      "    try:\n",
      "        print os.path.join(\"%s\" % plot_dir, \"%s\" % iip)\n",
      "        os.makedirs(os.path.join(\"%s\" % plot_dir, \"%s\" % iip))\n",
      "    except Exception as e:\n",
      "        print e\n",
      "\n",
      "    rankings[iip] = np.zeros((50, len(include_in_plots[iip])), dtype=np.float64)\n",
      "    for idx, dataset in enumerate(datasets):\n",
      "        dataset_rankings = np.zeros((50, len(include_in_plots)), dtype=np.float64)\n",
      "        for fold in range(num_folds):\n",
      "            dataset_dir = \"%s/did_%d_fold%d\" % (experiments_directory, dataset, fold)\n",
      "            plot_suffix = \"did_%d_fold%d\" % (dataset, fold)\n",
      "            if not os.path.isdir(dataset_dir) or \"did\" not in dataset_dir:\n",
      "                continue\n",
      "\n",
      "            print dataset_dir\n",
      "            num_datasets += 1\n",
      "\n",
      "            argument_list = []\n",
      "            for optimizer in include_in_plots[iip]:\n",
      "                pkls = glob.glob(optimizers[optimizer] % dataset_dir)\n",
      "                argument_list.append(optimizer)\n",
      "                argument_list.extend(pkls)\n",
      "\n",
      "            pkl_list_main, name_list_main = plot_util.get_pkl_and_name_list(argument_list)\n",
      "            ranking = meta_plot_util.plot_rankings(pkl_list_main, name_list_main, save=\"%s/%s/ranks_%s.pdf\" % (plot_dir, iip,  plot_suffix), figsize=(16,6))\n",
      "            #ranking = meta_plot_util.plot_rankings(pkl_list_main, name_list_main, save=\"%s/%s/ranks_%s.png\" % (plot_dir, iip,  plot_suffix), figsize=(16,6))\n",
      "            rankings[iip] += ranking\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/\n",
        "[Errno 17] File exists: '/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning/plots/'\n",
        "/home/feurerm/thesis/experiments/2014_06_01_AutoSklearn_metalearning//did_2_fold0\n",
        "0.0001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-0b9b56c5f094>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mpkl_list_main\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_list_main\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_pkl_and_name_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margument_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mranking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_plot_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_rankings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkl_list_main\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_list_main\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%s/%s/ranks_%s.pdf\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mplot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miip\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mplot_suffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[1;31m#ranking = meta_plot_util.plot_rankings(pkl_list_main, name_list_main, save=\"%s/%s/ranks_%s.png\" % (plot_dir, iip,  plot_suffix), figsize=(16,6))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mrankings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miip\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mranking\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/feurerm/thesis/Software/pyMetaLearn/pyMetaLearn/workflows/plot_utils.pyc\u001b[0m in \u001b[0;36mplot_rankings\u001b[1;34m(trial_list, name_list, optimum, title, log, save, y_min, y_max, cut, figsize, legend_ncols)\u001b[0m\n\u001b[0;32m     66\u001b[0m             ranks = scipy.stats.rankdata(\n\u001b[0;32m     67\u001b[0m                 [np.round(plot_util.get_best(pickles[optimizers[idx]][number], i), 5)\n\u001b[1;32m---> 68\u001b[1;33m                  for idx, number in enumerate(product)])\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mnum_products\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/feurerm/HPOlib/Software/HPOlib/HPOlib/Plotting/plot_util.pyc\u001b[0m in \u001b[0;36mget_best\u001b[1;34m(trials, cut)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_best\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;31m# returns the best value found in this experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mtraj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_trajectory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[0mbest_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcut\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/feurerm/HPOlib/Software/HPOlib/HPOlib/Plotting/plot_util.pyc\u001b[0m in \u001b[0;36mextract_trajectory\u001b[1;34m(trials, cut)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mcurrentbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"result\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trials'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################################################################################\n",
      "# draw a ranking graph averaged over all datasets\n",
      "num_datasets=57\n",
      "for iip in include_in_plots:\n",
      "    plt.figure(dpi=600, figsize=(9, 6))\n",
      "    ax = plt.subplot(111)\n",
      "    colors = plot_util.get_plot_colors()\n",
      "    ranks = rankings[iip] / float(num_datasets)\n",
      "    for i, optimizer in enumerate(include_in_plots[iip]):\n",
      "            ax.plot(range(1, 51), ranks[:, i], color=colors.next(),\n",
      "            linewidth=3, label=optimizer.replace(\"\\\\\", \"\"))\n",
      "\n",
      "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
      "              fancybox=True, shadow=True, ncol=3, labelspacing=0.25, fontsize=12)\n",
      "    box = ax.get_position()\n",
      "\n",
      "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
      "                 box.width, box.height * 0.9])\n",
      "    for plot_suffix in ['png', 'pdf']:\n",
      "        plt.savefig(\"%s/%s/all_datasets.%s\" % (plot_dir, iip, plot_suffix))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################\n",
      "# For a dataset, write out which hyperparameters are selected by all\n",
      "# metafeatures and the pfahringer metafeatures\n",
      "plot_dir = \"/home/feurerm/tmp/simple_metalearning_plots/\"\n",
      "num_folds = 1\n",
      "\n",
      "print \"WARNING: the ratio is overestimated as the metafeature computation time is for the whole dataset\" \\\n",
      "    \" and not only for the training set which contains only 2/3 of the data.\"\n",
      "for idx, did in enumerate(datasets):\n",
      "    for fold in range(num_folds):\n",
      "        dataset_dir = \"%s/did_%d_fold%d\" % (experiments_directory, did, fold)\n",
      "        plot_suffix = \"did_%d_fold%d\" % (did, fold)\n",
      "        if not os.path.isdir(dataset_dir) or \"did\" not in dataset_dir:\n",
      "            continue\n",
      "            \n",
      "        ground_truth = meta_plot_util.find_ground_truth(os.path.join(ground_truth_dir,\n",
      "                                                        \"did_%d_fold%s\" % (did, fold),\n",
      "                                                        \"sequential_optimization_*_\",\n",
      "                                                        \"sequential.pkl\"))\n",
      "        if not ground_truth:\n",
      "            continue\n",
      "        optimum, trial_index = plot_util.get_best_value_and_index(ground_truth)\n",
      "        best_parameters = ground_truth['trials'][trial_index]['params']\n",
      "        \n",
      "        dataset = pyMetaLearn.openml.manage_openml_data.get_local_dataset(did)\n",
      "        # Here should be a splitting file, as it isn't there, the costs are overestimated\n",
      "        metafeatures, calculation_time = dataset.get_metafeatures(return_times=True)\n",
      "        metafeatures_calculation_time = sum(calculation_time.values())\n",
      "        \n",
      "        # Somehow read the calculation time of the metafeatures\n",
      "        times = []\n",
      "        for trial in ground_truth['trials']:\n",
      "            #times.extend(trial['instance_durations'])\n",
      "            times.append(trial['duration'])\n",
      "        print did, np.nansum(times), np.nanmean(times), np.nanstd(times), np.nanmin(times), \\\n",
      "            np.nanmax(times), metafeatures_calculation_time, metafeatures_calculation_time / np.nanmean(times)\n",
      "        \"\"\"\n",
      "        metafeatures_all_file = glob.glob(\"%s/l1_allmetalearn_optimizer_*/l1_allmetalearn_optimizer.pkl\" % dataset_dir)\n",
      "        assert len(metafeatures_all_file) == 1\n",
      "        with open(metafeatures_all_file[0]) as fh:\n",
      "            metafeatures_all_trials = cPickle.load(fh)\n",
      "            \n",
      "        metafeatures_pfahringer_file = glob.glob(\"%s/l1_pfahringer_2000_experiment1\"\n",
      "            \"metalearn_optimizer_*/l1_pfahringer_2000_experiment1metalearn_optimizer.pkl\" % dataset_dir)\n",
      "        assert len(metafeatures_pfahringer_file) == 1\n",
      "        with open(metafeatures_pfahringer_file[0]) as fh:\n",
      "            metafeatures_pfahringer_trials = cPickle.load(fh)\n",
      "                        \n",
      "        with open(os.path.join(plot_dir, plot_suffix + \".txt\"), \"w\") as fh:\n",
      "            fh.write(str(best_parameters))\n",
      "            fh.write(\"\\n\")\n",
      "            for trial0, trial1 in itertools.izip(metafeatures_all_trials['trials'], metafeatures_pfahringer_trials['trials']):\n",
      "                fh.write(', '.join([str(param) + \": \" + trial0['params'][param] for param in trial0['params']]))\n",
      "                fh.write(\"   \")\n",
      "                fh.write(', '.join([str(param) + \": \" + trial1['params'][param] for param in trial1['params']]))\n",
      "                fh.write(\"\\n\")\n",
      "        \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: the ratio is overestimated as the metafeature computation time is for the whole dataset and not only for the training set which contains only 2/3 of the data.\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32708.18538 19.3998727046 16.9216967819 6.461938 107.7706 0.241198301315 0.0124329837101\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35689.695631 21.1682654988 27.2099123754 6.596638 248.79427 1.64406299591 0.0776664009624\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32470.081259 19.2586484336 19.8433017356 5.85908 150.22625 0.0423262119293 0.00219777686245\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35098.265402 20.8298310991 26.8960306468 6.962994 251.87085 1.93068432808 0.0926884293441\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 183924.977077 109.154289066 46.6936146146 9.101466 351.4259 5.83352589607 0.0534429379364\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33971.090444 20.1489267165 34.7585033956 6.295598 452.72464 0.236438751221 0.0117345581007\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30426.992705 18.0468521382 14.7644607992 6.048227 97.72849 0.0479505062104 0.00265700111261\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32763.856081 19.4328921002 20.0211435164 6.137262 179.50489 0.11451292038 0.00589273690139\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34579.535725 20.5098076661 48.1812579073 5.840813 1248.41247 0.0613312721253 0.00299033872593\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33788.740079 20.0407711026 19.8312810005 5.97888 133.74827 0.0502719879151 0.00250848570934\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13689.226422 8.11935137722 3.59258269301 4.801918 103.97096 5.48154306412 0.675120808233\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33190.56058 19.6859789917 16.7757156053 6.291105 98.99307 0.0799429416656 0.00406090759821\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35445.688516 21.0235400451 16.8447370846 6.819459 133.83968 3.08977985381 0.146967629961\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33850.903562 20.0776414958 19.9024997475 6.001243 136.0606 0.0668129920959 0.00332773110376\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36865.885955 21.8658872805 20.5264129749 6.567675 188.54325 2.41656279564 0.11051748162\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33594.58169 19.9256119158 18.1150325202 6.446858 170.238329 0.204252004623 0.0102507268277\n",
        "20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102119.939969 60.5693594122 25.506068937 9.519442 254.89834 91.1629590988 1.50510026825\n",
        "21"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33903.670701 20.1089387313 20.5567573434 6.405538 158.85003 0.21613574028 0.0107482420215\n",
        "22"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35223.945296 20.9044185733 20.0040124904 6.420843 136.54114 1.88865470886 0.09034715327\n",
        "23"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33039.519395 19.6080233798 16.8834140348 6.471711 129.44436 0.237909793854 0.0121332879529\n",
        "24"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41009.604381 24.3236087669 33.4545798761 9.654415 343.0561 11.8054220676 0.485348296002\n",
        "26"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 61135.98326 36.2609627877 21.8265089872 8.111842 209.93449 6.38417649269 0.176061968627\n",
        "28"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 68510.248899 40.6347858238 25.7265912208 6.811645 244.6 4.83049988746 0.118875977553\n",
        "29"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32676.399465 19.3810198488 20.7802815583 6.081961 230.080448 0.157516241074 0.00812734532562\n",
        "30"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 46547.564755 27.6082827728 28.3826277031 6.88947 627.52996 0.970296859741 0.0351451362522\n",
        "31"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34574.189938 20.5066369739 34.4033943787 6.509075 424.30977 0.306767702102 0.0149594349621\n",
        "32"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99047.199929 58.7468564229 43.5517091093 7.39031 1166.61886 2.28544855118 0.0389033335627\n",
        "33"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24107.376095 14.2985623339 12.4666004425 7.283667 188.77021 3.73315501213 0.261086039628\n",
        "34"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33423.03318 19.8238630961 20.071422266 5.988713 138.78403 0.0380351543426 0.00191865501483\n",
        "35"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34182.247141 20.2741679365 35.9835126316 6.139975 1076.04446 0.232799053192 0.0114825453711\n",
        "36"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34029.808513 20.1837535664 19.1933668865 6.307019 158.40088 0.458890914917 0.0227356578352\n",
        "37"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34057.722343 20.200309812 46.0943783256 5.93881 1136.76604 0.0850238800048 0.00420903841556\n",
        "39"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34052.728332 20.1973477651 45.7239485969 5.759429 1141.57943 0.0571594238281 0.00283004602846\n",
        "40"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33781.11029 20.0362457236 22.8443909656 6.19548 183.46946 0.158943653107 0.0079328061404\n",
        "41"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33933.007067 20.1263387112 35.6642386301 6.187106 544.99132 0.0532221794128 0.00264440443822\n",
        "42"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34207.044853 20.3009168267 34.6482895367 6.296491 1011.70183 0.384617328643 0.0189458107694\n",
        "43"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33749.079943 20.0291275626 23.2367775157 6.18295 183.82409 0.0499591827393 0.00249432645446\n",
        "44"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38650.51625 22.9243868624 34.6430019057 7.204989 1050.88247 2.18900465965 0.0954880351999\n",
        "48"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33718.596619 19.9991676269 23.1842226902 6.157184 190.38209 0.0361995697022 0.00181005381711\n",
        "49"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33644.685015 19.9553291904 22.9544833533 6.075868 200.45554 0.0627489089966 0.00314446874807\n",
        "50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30915.771693 18.3367566388 14.9940209288 6.211398 119.93304 0.13872718811 0.00756552485497\n",
        "51"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 31732.815241 18.8213613529 17.4496219078 5.991697 144.45858 0.0598773956299 0.00318135306513\n",
        "53"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33236.515631 19.7132358428 20.315333301 6.214153 154.85318 0.0681285858154 0.00345598187728\n",
        "54"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33656.959574 19.9626094745 27.0015965922 5.89597 246.98205 0.162240505219 0.00812721931097\n",
        "55"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32032.968129 18.9993879769 20.6755686998 5.902929 222.833666 0.0501921176911 0.00264177550099\n",
        "56"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33037.732311 19.5953335178 19.8061240051 6.013528 137.8096 0.0808861255646 0.0041278259179\n",
        "58"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32029.386133 18.9972634241 17.2879012593 6.376203 140.400339 0.286997795105 0.0151073230232\n",
        "59"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33626.994329 19.9448364941 27.6961748119 5.792987 275.903658 0.143494844437 0.00719458615162\n",
        "60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38155.751079 22.6309318381 19.5867586055 6.871949 173.34038 4.04508376121 0.178741370004\n",
        "61"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33637.98185 19.9513534104 45.3561001163 5.767015 1113.03267 0.0336322784424 0.0016857141343\n",
        "62"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32608.94059 19.3410086536 20.2491124415 6.071132 168.97181 0.0822966098787 0.00425503195581\n",
        "171"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33773.474309 20.0436049312 20.0183130645 6.064575 143.17782 0.117320299148 0.0058532534218\n",
        "181"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35217.257791 20.8880532568 48.6691271826 6.297446 1245.82912 0.175852298737 0.00841879789248\n",
        "182"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37393.75259 22.1789754389 20.2317186054 6.759928 144.89246 3.43035006523 0.154666750711\n",
        "183"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38440.575237 22.7998666886 19.5512530466 6.758839 142.04633 0.730318546295 0.0320317024774\n",
        "186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32988.761087 19.5662877147 21.7206414583 6.055849 248.118338 0.0814385414124 0.00416218664469\n",
        "188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35105.707404 20.8218905125 33.4829167206 6.38749 307.6944 0.354843616486 0.0170418539216\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.std([1.65, 1.75])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.050000000000000044"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}