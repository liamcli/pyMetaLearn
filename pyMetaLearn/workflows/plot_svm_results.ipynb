{
 "metadata": {
  "name": "",
  "signature": "sha256:32062f1715f023bf575230439db2baebcfc076caa6f35024d46ad40d4012478e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from argparse import ArgumentParser\n",
      "from collections import OrderedDict\n",
      "import cPickle\n",
      "import glob\n",
      "import itertools\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import scipy.stats\n",
      "import sys\n",
      "                                                                                                                                                                                                                                                                                                                                            \n",
      "%matplotlib inline\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib import rc\n",
      "rc('text', usetex=True)\n",
      "\n",
      "import HPOlib.Plotting.plot_util as plot_util\n",
      "import HPOlib.Plotting.generateTexTable as generate_tex_table\n",
      "import HPOlib.Plotting.plotTraceWithStd_perEval as plotTraceWithStd_perEval\n",
      "import HPOlib.Plotting.statistics as statistics\n",
      "\n",
      "import pyMetaLearn.openml.manage_openml_data\n",
      "import pyMetaLearn.metafeatures.metafeatures as mf_module\n",
      "from pyMetaLearn.openml.openml_task import OpenMLTask\n",
      "import pyMetaLearn.workflows.plot_utils as meta_plot_util"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ground_truth_dir = \"/home/feurerm/thesis/experiments/2014_04_17_gather_new_metadata_from_openml/\"\n",
      "experiments_directory = \"/home/feurerm/thesis/experiments/2014_04_23_simple_metalearning/\"\n",
      "plot_dir = os.path.join(experiments_directory, \"plots\")\n",
      "pyMetaLearn.openml.manage_openml_data.set_local_directory(\n",
      "    \"/home/feurerm/thesis/datasets/openml/\")\n",
      "local_directory = pyMetaLearn.openml.manage_openml_data.get_local_directory()\n",
      "openml_dataset_dir = os.path.join(local_directory, \"datasets\")\n",
      "    \n",
      "num_folds = 3\n",
      "try:\n",
      "    os.mkdir(plot_dir)\n",
      "except:\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset_list = glob.glob(os.path.join(openml_dataset_dir, \"did*.xml\"))\n",
      "datasets = []\n",
      "dataset_names = []\n",
      "for dataset_filename in dataset_list:\n",
      "    did = os.path.split(dataset_filename)[1]\n",
      "    did = int(did.replace(\"did\", \"\").replace(\".xml\", \"\"))\n",
      "\n",
      "    task_file = os.path.join(pyMetaLearn\n",
      "                .openml.manage_openml_data.get_local_directory(),\n",
      "                \"custom_tasks\", \"did_%d.pkl\" % did)\n",
      "    if not os.path.exists(task_file):\n",
      "        # print \"Skipping dataset %s\" % dataset_filename\n",
      "        continue\n",
      "        \n",
      "    with open(task_file) as fh:\n",
      "        task_dict = cPickle.load(fh)\n",
      "        \n",
      "    dataset = pyMetaLearn.openml.manage_openml_data.get_local_dataset(task_dict['data_set_id'])\n",
      "    dataset_names.append(dataset._name)\n",
      "    \n",
      "    datasets.append(did)\n",
      "datasets = datasets\n",
      "datasets.sort()\n",
      "\n",
      "print datasets, len(datasets)\n",
      "print dataset_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 171, 181, 182, 183, 186, 188] 57\n",
        "[u'vehicle', u'anneal.ORIG', u'segment', u'pendigits', u'mushroom', u'labor', u'abalone', u'diabetes', u'car', u'autos', u'mfeat-fourier', u'primary-tumor', u'waveform-5000', u'credit-a', u'letter', u'postoperative-patient-data', u'vowel', u'eucalyptus', u'cylinder-bands', u'ionosphere', u'mfeat-karhunen', u'balance-scale', u'mfeat-morphological', u'liver-disorders', u'dermatology', u'vote', u'breast-cancer', u'credit-g', u'soybean', u'arrhythmia', u'nursery', u'hepatitis', u'cmc', u'heart-c', u'glass', u'braziltourism', u'iris', u'heart-statlog', u'page-blocks', u'breast-w', u'heart-h', u'yeast', u'tae', u'haberman', u'mfeat-pixel', u'optdigits', u'mfeat-factors', u'satimage', u'lymph', u'audiology', u'ecoli', u'tic-tac-toe', u'spambase', u'zoo', u'sonar', u'mfeat-zernike', u'kr-vs-kp']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Assemble the list of optimizers\n",
      "bootstraps =  (2,) # 5) #, 10)\n",
      "distance = (\"l1\", \"l2\")# \"learned\")\n",
      "metafeature_subset = mf_module.subsets\n",
      "\n",
      "# Maybe some characters must be escaped\n",
      "optimizers = OrderedDict([\n",
      "    (\"SMAC\", \"%s/smac_2_06_01-dev_*/smac_2_06_01-dev.pkl\"),\n",
      "    (\"random\", \"%s/random_hyperopt_august2013_mod*/random_hyperopt_august2013_mod.pkl\"),\n",
      "    (\"TPE\", \"%s/hyperopt_august2013_mod_*/hyperopt_august2013_mod.pkl\"),\n",
      "    (\"Spearmint(Grid)\", \"%s/spearmint_gitfork_mod_*/spearmint_gitfork_mod.pkl\"),\n",
      "    #(\"MI-Spearmint(WS5,l1,landmarking)\", \"%s/bootstrapped5_l1_pfahringer_2000_experiment1spearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"), \n",
      "    #(\"MI-Spearmint(WS5,l1,all)\", \"%s/bootstrapped5_l1_allspearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"),\n",
      "    (\"MI-Spearmint(10,$L_1$,landmarking)\", \"%s/bootstrapped10_l1_pfahringer_2000_experiment1spearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"), \n",
      "    (\"MI-Spearmint(10,$L_1$,all)\", \"%s/bootstrapped10_l1_allspearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\")])\n",
      "    #(\"MI-Spearmint(15,$L_1$,landmarking)\", \"%s/bootstrapped15_l1_pfahringer_2000_experiment1spearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"), \n",
      "    #(\"MI-Spearmint(15,$L_1$,all)\", \"%s/bootstrapped15_l1_allspearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"),\n",
      "    #(\"MI-Spearmint(20,$L_1$,landmarking)\", \"%s/bootstrapped20_l1_pfahringer_2000_experiment1spearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"), \n",
      "    #(\"MI-Spearmint(20,$L_1$,all)\", \"%s/bootstrapped20_l1_allspearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"),\n",
      "    #(\"MI-Spearmint(25,$L_1$,landmarking)\", \"%s/bootstrapped25_l1_pfahringer_2000_experiment1spearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"), \n",
      "    #(\"MI-Spearmint(25,$L_1$,all)\", \"%s/bootstrapped25_l1_allspearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"),\n",
      "    #(\"MI-Spearmint(30,$L_1$,landmarking)\", \"%s/bootstrapped30_l1_pfahringer_2000_experiment1spearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\"), \n",
      "    #(\"MI-Spearmint(30,$L_1$,all)\", \"%s/bootstrapped30_l1_allspearmint_gitfork_mod_*/*spearmint_gitfork_mod.pkl\")])\n",
      "\n",
      "#for dist, subset in itertools.product(distance, metafeature_subset, repeat=1):\n",
      "#    optimizers[\"ML_%s_%s\" % (dist, subset)] = \\\n",
      "#        \"%s\" + \"/%s_%smetalearn_optimizer*/*metalearn_optimizer.pkl\" % (dist, subset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_folds = 1 # 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the error trace over all experiments\n",
      "include_in_plots = {\"\": optimizers,\n",
      "                    \"smbo\": [\"SMAC\", \"TPE\", \"random\", \"Spearmint(Grid)\"],\n",
      "                    \"bs\": [\"Spearmint(Grid)\", \"MI-Spearmint(10,$L_1$,landmarking)\", \"MI-Spearmint(10,$L_1$,all)\"]}\n",
      "\n",
      "for iip in include_in_plots:\n",
      "    try:\n",
      "        print os.path.join(\"%s\" % plot_dir, \"%s\" % iip)\n",
      "        os.makedirs(os.path.join(\"%s\" % plot_dir, \"%s\" % iip))\n",
      "    except Exception as e:\n",
      "        print e\n",
      "        \n",
      "    gigantic_pickle_list = [[] for optimizer in include_in_plots[iip]]\n",
      "    for idx, dataset in enumerate(datasets):\n",
      "        dataset_rankings = np.zeros((50, len(include_in_plots[iip])), dtype=np.float64)\n",
      "        for fold in range(num_folds):\n",
      "            dataset_dir = \"did_%d_fold%d\" % (dataset, fold)\n",
      "            exp_dir = os.path.join(experiments_directory, dataset_dir)\n",
      "            argument_list = []\n",
      "            for optimizer in include_in_plots[iip]:\n",
      "                pkls = glob.glob(optimizers[optimizer] % exp_dir)\n",
      "                argument_list.append(optimizer)\n",
      "                argument_list.extend(pkls)\n",
      "            try:\n",
      "                pkl_list_main, name_list_main = plot_util.get_pkl_and_name_list(argument_list)\n",
      "            except ValueError as e:\n",
      "                print \"Value Error in dataset directory %s\" % dataset_dir\n",
      "                raise ValueError\n",
      "            for i, optimizer in enumerate(include_in_plots[iip]):\n",
      "                gigantic_pickle_list[i].extend(pkl_list_main[i])\n",
      "        \n",
      "    for file_suffix in [\"png\", \"pdf\"]:\n",
      "        plotTraceWithStd_perEval.main(gigantic_pickle_list, name_list_main, True,\n",
      "                                      save=\"%s/%s/all_datasets_error.%s\" % (plot_dir, iip, file_suffix),\n",
      "                                      markers=False, linewidth=1, linestyle=True, y_max=0.4)\n",
      "        plotTraceWithStd_perEval.main(gigantic_pickle_list, name_list_main, True,\n",
      "                                      save=\"%s/%s/all_datasets_log_error.%s\" % (plot_dir, iip, file_suffix),\n",
      "                                      log=True, markers=False, linewidth=1, linestyle=True, y_max=-0.5, y_min=-0.9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the per-dataset error traces\n",
      "best_parameters = dict()\n",
      "\n",
      "include_in_plots = {\"\": optimizers,\n",
      "                    \"smbo\": [\"SMAC\", \"TPE\", \"random\", \"Spearmint(Grid)\"],\n",
      "                    \"bs\": [\"Spearmint(Grid)\", \"MI-Spearmint(10,$L_1$,landmarking)\", \"MI-Spearmint(10,$L_1$,all)\"]}\n",
      "\n",
      "for iip in include_in_plots:\n",
      "    try:\n",
      "        print os.path.join(\"%s\" % plot_dir, \"%s\" % iip)\n",
      "        os.makedirs(os.path.join(\"%s\" % plot_dir, \"%s\" % iip))\n",
      "    except Exception as e:\n",
      "        print e\n",
      "    \n",
      "    for idx, dataset in enumerate(datasets):\n",
      "        for fold in range(num_folds):\n",
      "            dataset_dir = \"%s/did_%d_fold%d\" % (experiments_directory, dataset, fold)\n",
      "            plot_suffix = \"did_%d_fold%d\" % (dataset, fold)\n",
      "            if not os.path.isdir(dataset_dir) or \"did\" not in dataset_dir:\n",
      "                continue\n",
      "\n",
      "            argument_list = []\n",
      "            for optimizer in optimizers:\n",
      "                if optimizer in include_in_plots[iip]:\n",
      "                    pkls = glob.glob(optimizers[optimizer] % dataset_dir)\n",
      "                    argument_list.append(optimizer)\n",
      "                    argument_list.extend(pkls)\n",
      "\n",
      "            pkl_list_main, name_list_main = plot_util.get_pkl_and_name_list(argument_list)\n",
      "\n",
      "            ground_truth = meta_plot_util.find_ground_truth(os.path.join(ground_truth_dir,\n",
      "                                                            \"did_%d_fold%s\" % (dataset, fold),\n",
      "                                                            \"gridsearch_*\",\n",
      "                                                            \"gridsearch.pkl\"))\n",
      "            if not ground_truth:\n",
      "                continue\n",
      "\n",
      "            ########################################################################\n",
      "            # Plot error traces for one dataset\n",
      "            optimum, trial_index = plot_util.get_best_value_and_index(ground_truth)\n",
      "            best_parameters[dataset] = ground_truth['trials'][trial_index]['params']\n",
      "\n",
      "            for file_suffix in [\"png\", \"pdf\"]:\n",
      "                plotTraceWithStd_perEval.main(pkl_list_main, name_list_main, True, \n",
      "                                          save=\"%s/%s/error_trace_%s.%s\" % (plot_dir, iip, plot_suffix, file_suffix),\n",
      "                                          markers=False, linewidth=1, linestyle=True);\n",
      "                \n",
      "                plotTraceWithStd_perEval.main(pkl_list_main, name_list_main, True, log=True, \n",
      "                                          save=\"%s/%s/error_trace_log_%s.%s\" % (plot_dir, iip, plot_suffix, file_suffix),\n",
      "                                          markers=False, linewidth=1, linestyle=True);\n",
      "\n",
      "                plotTraceWithStd_perEval.main(pkl_list_main, name_list_main, True, optimum=optimum,\n",
      "                                          save=\"%s/%s/optimum_error_trace_%s.%s\" % (plot_dir, iip, plot_suffix, file_suffix),\n",
      "                                          markers=False, linewidth=1, linestyle=True);\n",
      "                \n",
      "                plotTraceWithStd_perEval.main(pkl_list_main, name_list_main, True, optimum=optimum, log=True,\n",
      "                                          save=\"%s/%s/optimum_error_trace_log_%s.%s\" % (plot_dir, iip, plot_suffix, file_suffix),\n",
      "                                          markers=False, linewidth=1, linestyle=True);\n",
      "                \n",
      "# Plot this to a file or something...\n",
      "# for idx, dataset in enumerate(datasets):\n",
      "#     print dataset, dataset_names[idx], best_parameters[dataset]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do the statistical stuff\n",
      "include_in_plots = {\"\": optimizers,\n",
      "                    \"smbo\": [\"SMAC\", \"TPE\", \"random\", \"Spearmint(Grid)\"],\n",
      "                    \"bs\": [\"Spearmint(Grid)\", \"MI-Spearmint(10,$L_1$,landmarking)\", \"MI-Spearmint(10,$L_1$,all)\"]}\n",
      "reload(meta_plot_util)\n",
      "reload(plotTraceWithStd_perEval)\n",
      "for iip in include_in_plots:\n",
      "    try:\n",
      "        print os.path.join(\"%s\" % plot_dir, \"%s\" % iip)\n",
      "        os.makedirs(os.path.join(\"%s\" % plot_dir, \"%s\" % iip))\n",
      "    except Exception as e:\n",
      "        print e\n",
      "    \n",
      "    trial_list_per_dataset = []\n",
      "    trial_list_per_dataset2 = []\n",
      "    for fold in range(num_folds):\n",
      "        for idx, dataset in enumerate(datasets):\n",
      "            dataset_dir = \"%s/did_%d_fold%d\" % (experiments_directory, dataset, fold)\n",
      "            if not os.path.isdir(dataset_dir) or \"did\" not in dataset_dir:\n",
      "                continue\n",
      "\n",
      "            argument_list = []\n",
      "            for optimizer in optimizers:\n",
      "                if optimizer in include_in_plots[iip]:\n",
      "                    pkls = glob.glob(optimizers[optimizer] % dataset_dir)\n",
      "                    argument_list.append(optimizer)\n",
      "                    argument_list.extend(pkls)\n",
      "\n",
      "            pkl_list_main, name_list_main = plot_util.get_pkl_and_name_list(argument_list)\n",
      "            trial_list_per_dataset.append(pkl_list_main)\n",
      "\n",
      "    for file_suffix in [\"png\", \"pdf\"]:\n",
      "        meta_plot_util.plot_summed_wins_of_optimizers(\n",
      "            trial_list_per_dataset, name_list_main, legend_ncols=3, figsize=(16,6),\n",
      "            save=(\"%s/%s/percentage_of_wins_\" % (plot_dir, iip.replace(\"/\", \"_\")) + \"%s.\" + file_suffix))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the rankings\n",
      "num_folds = 1\n",
      "include_in_plots = {\"bs\": [\"Spearmint(Grid)\", \"MI-Spearmint(10,$L_1$,landmarking)\", \"MI-Spearmint(10,$L_1$,all)\"],\n",
      "                    \"smbo\": [\"SMAC\", \"TPE\", \"random\", \"Spearmint(Grid)\"],\n",
      "                    \"\": optimizers}\n",
      "rankings = {}\n",
      "\n",
      "for iip in include_in_plots:\n",
      "    num_datasets = 0\n",
      "    try:\n",
      "        print os.path.join(\"%s\" % plot_dir, \"%s\" % iip)\n",
      "        os.makedirs(os.path.join(\"%s\" % plot_dir, \"%s\" % iip))\n",
      "    except Exception as e:\n",
      "        print e\n",
      "\n",
      "    rankings[iip] = np.zeros((50, len(include_in_plots[iip])), dtype=np.float64)\n",
      "    for idx, dataset in enumerate(datasets):\n",
      "        dataset_rankings = np.zeros((50, len(include_in_plots)), dtype=np.float64)\n",
      "        for fold in range(num_folds):\n",
      "            dataset_dir = \"%s/did_%d_fold%d\" % (experiments_directory, dataset, fold)\n",
      "            plot_suffix = \"did_%d_fold%d\" % (dataset, fold)\n",
      "            if not os.path.isdir(dataset_dir) or \"did\" not in dataset_dir:\n",
      "                continue\n",
      "\n",
      "            print dataset_dir\n",
      "            num_datasets += 1\n",
      "\n",
      "            argument_list = []\n",
      "            for optimizer in include_in_plots[iip]:\n",
      "                pkls = glob.glob(optimizers[optimizer] % dataset_dir)\n",
      "                argument_list.append(optimizer)\n",
      "                argument_list.extend(pkls)\n",
      "\n",
      "            pkl_list_main, name_list_main = plot_util.get_pkl_and_name_list(argument_list)\n",
      "            ranking = meta_plot_util.plot_rankings(pkl_list_main, name_list_main, save=\"%s/%s/ranks_%s.pdf\" % (plot_dir, iip,  plot_suffix), figsize=(16,6))\n",
      "            #ranking = meta_plot_util.plot_rankings(pkl_list_main, name_list_main, save=\"%s/%s/ranks_%s.png\" % (plot_dir, iip,  plot_suffix), figsize=(16,6))\n",
      "            rankings[iip] += ranking\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################################################################################\n",
      "# draw a ranking graph averaged over all datasets\n",
      "\n",
      "for iip in include_in_plots:\n",
      "    \n",
      "    plt.figure(dpi=600, figsize=(9, 6))\n",
      "    ax = plt.subplot(111)\n",
      "    colors = plot_util.get_plot_colors()\n",
      "    ranks = rankings[iip] / float(num_datasets)\n",
      "    for i, optimizer in enumerate(include_in_plots[iip]):\n",
      "            ax.plot(range(1, 51), ranks[:, i], color=colors.next(),\n",
      "            linewidth=3, label=optimizer.replace(\"\\\\\", \"\"))\n",
      "\n",
      "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
      "              fancybox=True, shadow=True, ncol=3, labelspacing=0.25, fontsize=12)\n",
      "    box = ax.get_position()\n",
      "\n",
      "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
      "                 box.width, box.height * 0.9])\n",
      "    for plot_suffix in ['png', 'pdf']:\n",
      "        plt.savefig(\"%s/%s/all_datasets.%s\" % (plot_dir, iip, plot_suffix))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################\n",
      "# For a dataset, write out which hyperparameters are selected by all\n",
      "# metafeatures and the pfahringer metafeatures\n",
      "plot_dir = \"/home/feurerm/tmp/simple_metalearning_plots/\"\n",
      "num_folds = 1\n",
      "\n",
      "print \"WARNING: don't trust the times: back then, the datasets were preprocessed on the fly and there was this huge inference with the network...\"\n",
      "# The ratio is the percentage of average function evaluations that could have been performed during metafeature calculation\n",
      "print \"DID, total, mean, std, min, max, metafeatures, ratio\"\n",
      "for idx, did in enumerate(datasets):\n",
      "    for fold in range(num_folds):\n",
      "        dataset_dir = \"%s/did_%d_fold%d\" % (experiments_directory, did, fold)\n",
      "        plot_suffix = \"did_%d_fold%d\" % (did, fold)\n",
      "        if not os.path.isdir(dataset_dir) or \"did\" not in dataset_dir:\n",
      "            continue\n",
      "            \n",
      "        dataset = pyMetaLearn.openml.manage_openml_data.get_local_dataset(did)\n",
      "        # Here should be a splitting file, as it isn't there, the costs are overestimated\n",
      "        metafeatures, calculation_time = dataset.get_metafeatures(return_times=True)\n",
      "        metafeatures_calculation_time = sum(calculation_time.values())\n",
      "            \n",
      "        ground_truth = meta_plot_util.find_ground_truth(os.path.join(ground_truth_dir,\n",
      "                                                        \"did_%d_fold%s\" % (did, fold),\n",
      "                                                        \"gridsearch_*\",\n",
      "                                                        \"gridsearch.pkl\"))\n",
      "        if not ground_truth:\n",
      "            continue\n",
      "        optimum, trial_index = plot_util.get_best_value_and_index(ground_truth)\n",
      "        best_parameters = ground_truth['trials'][trial_index]['params']\n",
      "        \n",
      "        # Somehow read the calculation time of the metafeatures\n",
      "        times = []\n",
      "        for trial in ground_truth['trials']:\n",
      "            # times.extend(trial['instance_durations'])\n",
      "            times.append(trial['duration'])\n",
      "        print did, np.nansum(times), np.nanmean(times), np.nanstd(times), np.nanmin(times), \\\n",
      "            np.nanmax(times), metafeatures_calculation_time, metafeatures_calculation_time / np.nanmean(times)\n",
      "        \n",
      "        \"\"\"\n",
      "        metafeatures_all_file = glob.glob(\"%s/l1_allmetalearn_optimizer_*/l1_allmetalearn_optimizer.pkl\" % dataset_dir)\n",
      "        assert len(metafeatures_all_file) == 1\n",
      "        with open(metafeatures_all_file[0]) as fh:\n",
      "            metafeatures_all_trials = cPickle.load(fh)\n",
      "            \n",
      "        metafeatures_pfahringer_file = glob.glob(\"%s/l1_pfahringer_2000_experiment1\"\n",
      "            \"metalearn_optimizer_*/l1_pfahringer_2000_experiment1metalearn_optimizer.pkl\" % dataset_dir)\n",
      "        assert len(metafeatures_pfahringer_file) == 1\n",
      "        with open(metafeatures_pfahringer_file[0]) as fh:\n",
      "            metafeatures_pfahringer_trials = cPickle.load(fh)\n",
      "                        \n",
      "        with open(os.path.join(plot_dir, plot_suffix + \".txt\"), \"w\") as fh:\n",
      "            fh.write(str(best_parameters))\n",
      "            fh.write(\"\\n\")\n",
      "            for trial0, trial1 in itertools.izip(metafeatures_all_trials['trials'], metafeatures_pfahringer_trials['trials']):\n",
      "                fh.write(', '.join([str(param) + \": \" + trial0['params'][param] for param in trial0['params']]))\n",
      "                fh.write(\"   \")\n",
      "                fh.write(', '.join([str(param) + \": \" + trial1['params'][param] for param in trial1['params']]))\n",
      "                fh.write(\"\\n\")\n",
      "        \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: don't trust the times: back then, the datasets were preprocessed on the fly and there was this huge inference with the network...\n",
        "DID, total, mean, std, min, max, metafeatures, ratio\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 22230.22196 55.8548290452 25.0695326733 16.57437 118.41973 0.360172271729 0.00644836405169\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3 36196.72674 90.7186133835 34.4656551336 47.81254 169.4354 1.69149208069 0.0186454798812\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4 18837.32024 47.2113289223 20.3737888597 11.94142 102.21892 0.0468273162842 0.00099186609132\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5 26683.44599 67.0438341457 27.3181896711 25.72629 137.876 2.02422952652 0.0301926277384\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6 77433.2544 194.068306767 103.80830343 53.59334 421.8294 5.85165190697 0.0301525375495\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7 19224.5491 48.1818273183 16.1900270603 15.19781 85.76504 0.27226471901 0.00565077611547\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8 14768.604752 37.0140469975 15.4787110941 9.686905 79.01486 0.0485136508942 0.00131068215528\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9 15666.64669 39.2647786717 15.9781416206 10.514345 82.9442 0.123634815216 0.00314874601102\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 18810.196422 47.1433494286 24.3272520738 11.33513 106.58857 0.0688681602478 0.00146082450828\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 20196.43571 50.6176333584 25.4656136586 12.51856 114.99908 0.0510203838349 0.00100795672278\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12 31842.02258 79.8045678697 30.6268712791 35.42414 153.5187 5.57728195191 0.0698867508564\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13 18708.805555 46.8892369799 23.8733198805 11.58327 107.04417 0.0860211849213 0.00183456141455\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14 24647.8076 61.7739538847 27.3213980323 19.56861 127.33387 3.10546398162 0.0502714135381\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15 21195.41198 53.1213332832 27.7106540474 12.65229 124.54793 0.0678789615631 0.00127780982456\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "16 25335.70003 63.6575377638 29.7178749871 18.18807 141.93687 2.43066763878 0.0381835007159\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "18 22912.25596 57.424200401 30.143713833 13.72444 144.9745 0.206011295318 0.00358753441719\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20 97600.1414 244.611883208 38.3999044848 180.8488 325.178 98.3471662998 0.40205391909\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21 20891.44624 52.359514386 23.5071256201 15.35923 106.11369 0.222160816193 0.00424298847684\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "22 22663.23611 56.8000905013 23.716791801 17.32373 111.16237 1.89828586578 0.0334204725561\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "23 24395.69713 61.1420980702 27.9303191515 17.81129 127.22935 0.244488477707 0.00399869296972\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24 52870.19598 132.506756842 45.5426331712 70.19473 266.9986 11.9705462456 0.0903391384021\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "26 55603.43707 139.356985138 62.023337768 54.99 391.1533 6.41672134399 0.0460452078354\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "28 33380.03985 83.6592477444 31.261553843 24.29613 159.4663 4.86480784415 0.0581502699979\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "29 20277.28263 50.820257218 24.7125161181 13.4356 105.86555 0.166211128235 0.00327056841766\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "30 28504.72416 71.4404114286 30.7684691362 20.47239 143.0083 0.974988937378 0.0136475829\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "31 22919.93547 57.4434472932 26.9693149954 16.12468 121.58893 0.319603681564 0.00556379703211\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "32 39740.88714 99.6012209023 41.0289472381 18.0034 205.6395 2.29656553268 0.023057604233\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "33 23699.7216 59.3977984962 26.7703706143 17.85201 122.2226 4.04701519013 0.0681340940672\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "34 19749.528503 49.4975651704 26.4122742563 11.90808 119.07214 0.0418553352356 0.00084560392196\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "35 17528.34527 43.9306898997 18.6506473295 14.04523 98.14596 0.258717298508 0.0058892154687\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "36 16989.71721 42.5807448872 18.3998856764 13.19316 96.19455 0.463496685028 0.0108851239276\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "37 14730.187911 36.917764188 18.425065989 9.690439 97.24594 0.0861036777496 0.00233231019385\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "39 20637.14145 51.852114196 21.6176678329 14.24174 114.68669 0.0578453540801 0.00111558332726\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "40 20942.13656 52.4865577945 21.6036904205 13.21738 112.98924 0.162743330002 0.00310066685339\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "41 17814.852825 44.7609367462 18.407435656 10.849578 88.47079 0.0539753437042 0.00120585822433\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "42 24170.79498 60.5784335338 25.6718183501 18.26697 124.37364 0.411813735961 0.0067980255008\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "43 20011.1824 50.1533393484 20.8386444692 12.93895 101.46697 0.0515019893646 0.00102689053279\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "44 27836.92727 69.7667350125 26.7028643614 27.64141 138.525 2.21378350258 0.0317312183547\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "48 19081.34005 47.8229073935 20.0636003906 12.05558 93.79503 0.0377914905548 0.00079023824804\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "49 19518.28608 48.9180102256 20.3612885484 12.64786 103.69638 0.0669689178467 0.00136900330855\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "50 20427.47168 51.1966708772 21.397842612 14.62212 103.97981 0.145138025284 0.00283491138773\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "51 19147.68625 47.9891885965 19.8435676067 12.22795 99.72742 0.0642161369324 0.00133813758495\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "53 19710.59661 49.3999915038 20.184072942 12.46219 104.13843 0.0688705444336 0.00139414081536\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "54 19848.3415 49.745216792 20.3442548953 13.35888 114.3857 0.164345741272 0.00330374962399\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "55 20282.0836 50.8322897243 21.2066655732 13.93247 110.51479 0.0562400817871 0.00110638497876\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "56 21346.24539 53.4993618797 22.2974847127 13.49861 101.58619 0.0890510082245 0.00166452468022\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "58 21319.80879 53.4331047368 22.3913122932 14.75497 110.08404 0.293052911759 0.00548448219886\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "59 18686.659611 46.8337333609 19.8953583808 11.60653 95.04689 0.145889043808 0.00311504194388\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "60 26436.85021 66.2577699499 25.423414165 21.01339 127.35776 4.06167769432 0.0613011530179\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "61 18165.944119 45.5286820025 20.1145707324 11.129016 104.08833 0.0342042446137 0.000751268060248\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "62 18699.836275 46.8667575815 20.4388260733 11.47192 101.03309 0.0924828052522 0.00197331349606\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "171 9054.198289 22.6922262882 4.44867356589 12.333306 36.09597 0.124878406525 0.00550313596112\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "181 8927.593927 22.3749221228 8.34992994841 11.508283 80.9855 0.177677154541 0.00794090605392\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "182 17756.36927 44.6139931407 11.6355172209 26.16953 78.47638 3.44578671455 0.0772355593386\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "183 17045.60166 42.7208061654 45.8857962806 19.84589 438.254 0.734811306 0.0172003145997\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "186 8429.537387 21.1266601178 4.18039530819 11.44012 33.55561 0.0846333503724 0.0040059976305\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "188 9170.330307 22.9832839774 4.62722800579 12.3859 36.62737 0.366699457169 0.0159550505284\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}